{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e1c0d1d-0fd8-4861-9b05-bdf8d3ab7a15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df95df6b-0cf8-45e6-b880-d5cefdd7bd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "236631e0-905a-42f8-8dc7-72e0acd5cd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e9f7f4f-23da-4a54-ae07-016160c67fe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('train_data.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "with open('val_data.pkl', 'rb') as f:\n",
    "    val_data = pickle.load(f)\n",
    "\n",
    "with open('test_data.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b496876-da7e-4598-aedd-3472ac90b74b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_COMPONENTS = 3\n",
    "INPUT_STEP = 10\n",
    "OUTPUT_STEP = 1\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcb5e5b-d63d-448e-a5ac-dff68b825ef8",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd43c65a-0b57-4a35-87aa-c8205ea98ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class HEDataset(Dataset):\n",
    "    def __init__(self, data, pca=None, mean=None, std=None):\n",
    "        print(\"Reduce dim\")\n",
    "        if not pca:\n",
    "            pca = PCA(n_components=N_COMPONENTS)\n",
    "            pca.fit(data)\n",
    "            print(pca.explained_variance_)\n",
    "        self.pca = pca\n",
    "        transformed_data = pca.transform(data)\n",
    "        timeframes = torch.Tensor(transformed_data)\n",
    "        \n",
    "        print(\"Data norm\")\n",
    "        if mean is None:\n",
    "            mean = timeframes.mean(0)\n",
    "        self.mean = mean\n",
    "        print(self.mean)\n",
    "        if std is None:\n",
    "            std = timeframes.std(0)\n",
    "        self.std = std\n",
    "        transformed_data = timeframes - self.mean\n",
    "        transformed_data = transformed_data / self.std\n",
    "        self.original = transformed_data # todo debug only\n",
    "        print(\"Unfold data into blocks\")\n",
    "        self.srcs = transformed_data[:-1].unfold(0, INPUT_STEP, 1).to(device)   # leave the last one for the last tgts\n",
    "        self.tgts = torch.unsqueeze(transformed_data[INPUT_STEP:], 2).to(device)\n",
    "        assert self.srcs.shape[0] == self.tgts.shape[0]\n",
    "        step = self.srcs.shape[0] // 2\n",
    "        assert torch.equal(self.srcs[step, :, -1].detach().unsqueeze(1), self.tgts[step-1, :, :].detach())\n",
    "        print(self.srcs.shape, self.tgts.shape)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = self.srcs[idx, :, :]\n",
    "        tgt = self.tgts[idx, :, :]\n",
    "        return src, tgt\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.srcs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecad95f5-3ed2-4396-86f7-54117331c808",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transformed_data = torch.Tensor(transformed_data).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07fea291-af13-4560-8ce7-64a192c9d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "291ab3ff-64ce-4db0-9078-2ab003c463d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "# 1 2 3 -> 4\n",
    "# 2 3 4 -> 5\n",
    "# Testing\n",
    "# 3 4 5 -> (6) todo mse of this step\n",
    "# 4 5 (6) -> (7) todo mse of this step\n",
    "# 5 (6) (7) -> (8) todo mse of this step\n",
    "# todo 5 is seen, so performance may be benefited from this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fea17333-9b52-417a-95c9-8353a353bc2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[133.81 ,  88.55 ,  61.88 , ...,  44.483,  44.483,  44.483],\n",
       "       [382.26 , 255.15 , 178.11 , ..., 127.37 , 127.37 , 127.37 ],\n",
       "       [762.26 , 509.43 , 355.46 , ..., 252.56 , 252.56 , 252.56 ],\n",
       "       ...,\n",
       "       [296.03 , 197.63 , 138.   , ...,  98.799,  98.799,  98.799],\n",
       "       [331.21 , 221.17 , 154.41 , ..., 110.47 , 110.47 , 110.47 ],\n",
       "       [121.58 ,  80.613,  56.355, ...,  40.592,  40.592,  40.592]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "159cbe4f-b0ad-40d9-9918-ae9441103b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduce dim\n",
      "[1.10035800e+06 2.67009012e+00 1.49567762e+00]\n",
      "Data norm\n",
      "tensor([-2.1191e-05,  6.7003e-09, -1.8680e-08])\n",
      "Unfold data into blocks\n",
      "torch.Size([4990, 3, 10]) torch.Size([4990, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "training_dataset = HEDataset(train_data[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70f1ade9-f26b-4e29-a125-3911c0564c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "_ = training_dataset.original.cpu().numpy()\n",
    "sns.histplot(_.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b22914df-4937-4957-aa4b-6e5a57507977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduce dim\n",
      "Data norm\n",
      "tensor([-2.1191e-05,  6.7003e-09, -1.8680e-08])\n",
      "Unfold data into blocks\n",
      "torch.Size([1990, 3, 10]) torch.Size([1990, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "validation_dataset = HEDataset(train_data[5000:7000], training_dataset.pca, training_dataset.mean, training_dataset.std)\n",
    "# validation_dataset = HEDataset(val_data, training_dataset.pca, training_dataset.mean, training_dataset.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "318673bc-65ef-485d-b205-c2f1927afe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c6632e2-5c60-4ee8-9370-b8a0c70e628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_val = DataLoader(validation_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f608e75-7c08-441f-9532-91b2eda284e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-1)\n",
    "    for epoch in range(7):  # loop over the dataset multiple times\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for data in tqdm(dataloader, \"Train\"):\n",
    "            optimizer.zero_grad()\n",
    "            src, tgt = data \n",
    "            outputs, _ = model(src)\n",
    "            l = loss(outputs, tgt)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            # print statistics\n",
    "            running_loss += l\n",
    "        print(f'[{epoch + 1}] loss: {running_loss/len(dataloader)}')\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            for data in tqdm(dataloader_val, \"Val\"):\n",
    "                src, tgt = data\n",
    "                outputs, _ = model(src)\n",
    "                l = loss(outputs, tgt)\n",
    "                running_loss += l\n",
    "            print(f'[{epoch + 1}] Val loss: {running_loss/len(dataloader_val)}') \n",
    "    return model  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a35607c-0012-4904-a8b4-1cda34bd91c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T14:27:26.010466Z",
     "iopub.status.busy": "2022-02-26T14:27:26.008818Z",
     "iopub.status.idle": "2022-02-26T14:27:26.017085Z",
     "shell.execute_reply": "2022-02-26T14:27:26.014688Z",
     "shell.execute_reply.started": "2022-02-26T14:27:26.010413Z"
    },
    "tags": []
   },
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa512dfc-a738-4e1f-bcf1-a5412573c52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "078d759ed67f4e9d9405be811b06d1f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 1.0014554262161255\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aee571dda5a482f8918584c00bde5f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/1990 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Val loss: 1.372548222541809\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc1b5f276824a349f7cc62f75aa84bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] loss: 1.0000848770141602\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127100fc03424aa6a232c44d6c1eff36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/1990 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] Val loss: 1.3721033334732056\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f591d0ff0a44ef28494244e3afb069c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] loss: 1.000082015991211\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "603a7f425d6a4a869e9094ce7c4bd671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/1990 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] Val loss: 1.3720958232879639\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "328e9462654e4d3cb5484ca0526cab0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] loss: 1.0000816583633423\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c91f6e211941c58a6cc7dddb652ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/1990 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] Val loss: 1.3720906972885132\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c02190f05824094a060b5230b94c1e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] loss: 1.0000805854797363\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ed210274bb4df088009898e9dc4b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/1990 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] Val loss: 1.3720892667770386\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "081275ef9b604b219b85e71527f945fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6] loss: 1.0000810623168945\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944de26100a24f6bb97a9e853f9d9494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/1990 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6] Val loss: 1.3720875978469849\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1a6b038b1945109184f136af76cdc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7] loss: 1.0000807046890259\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33bf6da1f87455aa220085c34abc77e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/1990 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7] Val loss: 1.3720874786376953\n"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(INPUT_STEP, OUTPUT_STEP, 8, batch_first=True).to(device)\n",
    "lstm = train(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed79eb72-a0b0-49c8-9a68-796d0e757a4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_reconstruct_data(pca, mean, std, model, dataloader):\n",
    "    outputs = []    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _, data in list(enumerate(tqdm(dataloader, \"Predict\"))):  # enumerate to reset the dataloader\n",
    "            src, _ = data\n",
    "            if type(model) == torch.nn.modules.rnn.LSTM:\n",
    "                output, _ = model(src)                \n",
    "            else:\n",
    "                output = model(src)            \n",
    "            outputs.append(output.reshape(N_COMPONENTS))\n",
    "        # Unnormalized the data\n",
    "        outputs = torch.stack(outputs, dim=0)\n",
    "        outputs = outputs * std.to(device)\n",
    "        outputs = outputs + mean.to(device)\n",
    "        reconstructed_sklearn = pca.inverse_transform(outputs.cpu().numpy())\n",
    "        return reconstructed_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d71ced2f-66c7-475d-b04a-b87939602f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a1deac42b6d4a61a7f89c8cf1744f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predict:   0%|          | 0/1990 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reconstruct_lstm = predict_reconstruct_data(training_dataset.pca, training_dataset.mean, training_dataset.std, lstm, dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a232dd85-d5ee-4fa1-bce5-5a571de66fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_reconstructed(receive, expected):\n",
    "    print(f\"Receive shape: {receive.shape}. Expected shape: {expected.shape}\")\n",
    "    return mse(receive, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c15d2cfc-514b-4752-bc60-28e3917f8717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6323.864398371921"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(reconstruct_lstm, train_data[5000+INPUT_STEP:7000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d52acf-980e-402a-85a0-b72b5fddbcb3",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7f049e8-c76a-44d7-b116-37716d4af645",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()\n",
    "#transformer_model = nn.Transformer(nhead=N_COMPONENTS, num_encoder_layers=32,   # d_model divisible by nhead\n",
    "#                                   d_model=N_COMPONENTS, batch_first=True).to(device)\n",
    "transformer_model = nn.Transformer(nhead=N_COMPONENTS, num_encoder_layers=32,   # d_model divisible by nhead\n",
    "                                   d_model=N_COMPONENTS).to(device)\n",
    "optimizer = optim.Adam(transformer_model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c95eb565-ed0c-48b1-9659-db40a6609667",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_tf(model):\n",
    "    model.train()\n",
    "    loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-8)\n",
    "    for epoch in range(3):  # loop over the dataset multiple times\n",
    "        for i in tqdm(range(srcs.shape[1]//100)):\n",
    "            optimizer.zero_grad()\n",
    "            running_loss = 0.0\n",
    "\n",
    "            src = srcs[:,i,:].T\n",
    "            tgt = torch.unsqueeze(tgts[:,i], dim=0)\n",
    "            outputs = model(src, tgt)\n",
    "            l = loss(outputs, tgt)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += l\n",
    "        print(f'[{epoch + 1}] loss: {running_loss / 2000:}')\n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fde9e67-b8ca-488c-85eb-0dab20b06c3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'srcs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/datadrive/minh/ipykernel_1933/3190729371.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransformer_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_tf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/datadrive/minh/ipykernel_1933/1487823757.py\u001b[0m in \u001b[0;36mtrain_tf\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# loop over the dataset multiple times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'srcs' is not defined"
     ]
    }
   ],
   "source": [
    "transformer_model = train_tf(transformer_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093f8a50-5a09-4712-a938-344a0b93781e",
   "metadata": {},
   "source": [
    "## Reconstruct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf39dc1-b047-4d40-a547-d4d73cd885cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(p_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d533a267-0305-4371-a723-d0a1c7b632af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c066ac37-9111-4e41-980d-9861d418da57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformer_model.eval()\n",
    "transformer_eval = transformed_data.copy()\n",
    "for i in range(4, p_data.shape[1]-1):\n",
    "    print(transformer_eval.shape)\n",
    "    predict = transformer_model(torch.unsqueeze(torch.FloatTensor(transformer_eval[-2-INPUT_STEP:-2]), 0),  # INPUT_STEP steps before\n",
    "                               torch.unsqueeze(torch.FloatTensor(transformer_eval[-1:]), 0))\n",
    "    print(predict.shape)\n",
    "    transformer_eval = np.append(transformer_eval, predict[0].detach().numpy(), axis=0)  # append prediction and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86032518-f88d-4826-955a-0bdcb777affe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformer_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc5a28b-f84b-4119-a564-d0a48d39dbb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reconstruct(transformer_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9ed1b3-c2a4-4ed3-a4fb-d7c58224bb97",
   "metadata": {},
   "source": [
    "todo\n",
    "\n",
    "10s\n",
    "10.1s\n",
    "10.2s\n",
    "\n",
    "a common algo to reduce dim, pca. \n",
    "- look at robustness for prediction further in time.\n",
    "    - how to get more data simscale. Horizon 8 hours, train 6h, predict 2h. First step 10 mins\n",
    "        - Increase data slowly, see the limit of ML methods\n",
    "        - Tradition ML (lstm, transformers) will have problem. How long can we predict using this?\n",
    "            - Change ML approach maybe to operator inference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
